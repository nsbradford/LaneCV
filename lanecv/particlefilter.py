"""
	particlefilter.py
	3/29/2017
	Nicholas S. Bradford

"""

import numpy as np

from .model import MultiModel, LineModel
from .config import Constants


class ParticleFilterModel():

    LEARNING_RATE = 1e-2
    VAR_OFFSET = LineModel.OFFSET_RANGE / 100
    VAR_ORIENTATION = LineModel.ORIENTATION_RANGE / 100
    VISUALIZATION_SIZE = 300
    

    def __init__(self, n=1000):
        self.state_size = 2
        self.n = n
        self.particles = self._init_particles()
        self.weights = self._init_weights()
        self.state_matrix = self._init_state()
        self.state = None
        assert self.particles.shape == (self.n,self.state_size), self.particles.shape
        assert self.weights.shape == (self.n,), self.weights.shape
        assert self.state_matrix.shape == (self.state_size,), self.state_matrix.shape


    def updateState(self, model_measurement):
        """ This is the ONLY public method!
        
            Perform a complete update step.
            Args:
                state_measurement (State): evidence generated by RANSAC on a single frame
            Returns:
                self.state (State): the new State estimate

        """
        measurement = LineModel.modelToMatrix(model_measurement)
        return self._update(measurement)


    def updateStateNoEvidence():
        # TODO should still update somewhat by applying noise
        return self.state


    def _init_particles(self):
        p_offset = np.random.uniform(low=LineModel.OFFSET_MIN, high=LineModel.OFFSET_MAX, 
                            size=self.n)
        p_orientation = np.random.uniform(low=LineModel.ORIENTATION_MIN, 
                            high=LineModel.ORIENTATION_MAX, size=self.n)
        return np.vstack((p_offset, p_orientation)).T


    def _init_weights(self):
        """ Initialize to a uniform distribution"""
        w = np.ones((self.n,))
        w /= np.sum(w)
        return w


    def _init_state(self):
        """ Requires particles and weights to have been initialized."""
        return self._calc_state()


    def _update(self, measurement):
        """ Perform a complete update step.
            Args:
                measurement 
            Returns:
                self.state (State)

            Algorithm for Particle Filter:
            def f (S, U, Z): # S is particles, U is control, Z is measurement
                S' = empty set
                for i = 0 ... n: # each new particle
                    Sample J ~ {w} with replacement # weights of current S
                    Estimate x' ~ p(x' | U, s_j)
                    W' = p(z|x') # new particle weight is likelihood given estimate
                    S' = S' u {< x', w'>} # add new particle to set
                for i = 0 ... n: # for each particle,  normalize weights
                    W_i /= n

        """
        assert measurement.shape == (self.state_size,)
        resampled_indices = np.random.choice(a=self.n, size=self.n, replace=True, p=self.weights)
        resampled_particles = self.particles[resampled_indices, :]
        self.particles = self._apply_control(resampled_particles)
        self.weights = 1 /( 1 + ParticleFilterModel._distance(self.particles, measurement))
        self.weights /= np.sum(self.weights)
        self.state_matrix = self._calc_state()
        assert self.particles.shape == (self.n,self.state_size), self.particles.shape
        assert self.weights.shape == (self.n,), self.weights.shape
        assert self.state_matrix.shape == (self.state_size,), self.state_matrix.shape
        self.state = LineModel.matrixToModel(self.state_matrix)
        return self.state


    def _apply_control(self, resampled_particles):
        """ Apply control model (motion of the plane).
            For now, model as Gaussian noise applied to each particle,
                which prevents all particles collapsing to a single point.
        """
        noise1 = np.random.normal(0, ParticleFilterModel.VAR_OFFSET, (self.n, 1))
        noise2 = np.random.normal(0, ParticleFilterModel.VAR_ORIENTATION, (self.n, 1))
        noise = np.hstack((noise1, noise2))
        return resampled_particles + noise


    def _calc_state(self):
        """ Estimate the state given the current distribution of particles;
            Return the mean position.
        """
        return np.average(a=self.particles, axis=0, weights=self.weights) # for each column


    @staticmethod
    def _distance(new_particles, measurement):
        """ Get distance from each particle in the list to a measurement.
                Use squared distance. Average of 2 columns, for each row.
                Normalize by the expected variance of true values.
                Tune the Learning Rate to change the magnitude of the distance;
                    larger rate will cause particles to move more quickly.
            Args:
                new_particles (np.array): n x state_size list of particles
                measurement (np.array): state_size x 1 
        """
        transform = np.array([1000/LineModel.OFFSET_RANGE, 1000/LineModel.ORIENTATION_RANGE])
        normalized_particles = new_particles * transform
        normalized_measurement = measurement * transform
        distances = ((normalized_particles - normalized_measurement) ** 2)
        answer = distances.mean(axis=1)
        return answer * ParticleFilterModel.LEARNING_RATE



class MetaModel():
    """ A combination of 1 or more ParticleFilterModels. """

    def __init__(self):
        self.pfmodel = ParticleFilterModel()

    def updateState(self, multimodel):
        if multimodel is None:
            return self.pfmodel.updateStateNoEvidence()
        else:
            multimodel = MetaModel._choose_between_models(multimodel, self.pfmodel.state_matrix)
            return self.pfmodel.updateState(multimodel.model1)


    @staticmethod
    def _choose_between_models(multimodel, last_measurement):
        """
            Args:
                multimodel (MultiModel): new evidence
                last_measurement (np.array): previous model
            Returns:
                MultiModel
        """
        m1 = multimodel.model1
        m2 = multimodel.model2
        if multimodel.model2 is not None and last_measurement is not None:
            observations = np.array([   [m1.offset, m1.orientation],
                                        [m2.offset, m2.orientation]])
            distance = ParticleFilterModel._distance(new_particles=observations, 
                                measurement=last_measurement)
            print('\t\tChoice 1 dist {0:.2f}: \toffset {1:.2f} \t orientation {2:.2f}'.format(
                                distance[0], m1.offset, m1.orientation))
            print('\t\tChoice 2 dist {0:.2f}: \toffset {1:.2f} \t orientation {2:.2f}'.format(
                                distance[1], m2.offset, m2.orientation))
            if distance[0] > distance[1]:
                m1, m2 = m2, m1
        return MultiModel(m1, m2)