"""
	particlefilter.py
	3/29/2017
	Nicholas S. Bradford

"""

import numpy as np

from .config import Constants


class ParticleFilterModel():

    LEARNING_RATE = 1e-3
    VISUALIZATION_SIZE = 500
    

    def __init__(self, particle_cls, n=1000):
        VAR_SCALING = 100
        self.particle_cls = particle_cls
        self.VAR_OFFSET = particle_cls.OFFSET_RANGE / VAR_SCALING
        self.VAR_ORIENTATION = particle_cls.ORIENTATION_RANGE / VAR_SCALING
        self.state_size = 2
        self.n = n
        self.particles = self._init_particles()
        self.weights = self._init_weights()
        self.state_matrix = self._init_state()
        self.state = None
        self.last_measurement = None # Used only for plotting
        assert self.particles.shape == (self.n,self.state_size), self.particles.shape
        assert self.weights.shape == (self.n,), self.weights.shape
        assert self.state_matrix.shape == (self.state_size,), self.state_matrix.shape


    def updateState(self, model_measurement):
        """ This is the ONLY public method!
        
            Perform a complete update step.
            Args:
                state_measurement (State): evidence generated by RANSAC on a single frame
            Returns:
                self.state (State): the new State estimate

        """
        measurement = self.particle_cls.modelToMatrix(model_measurement)
        return self._update(measurement)


    def updateStateNoEvidence(self):
        # TODO should still update somewhat by applying noise
        return self.state


    def _init_particles(self):
        p_offset = np.random.uniform(low=self.particle_cls.OFFSET_MIN, high=self.particle_cls.OFFSET_MAX, 
                            size=self.n)
        p_orientation = np.random.uniform(low=self.particle_cls.ORIENTATION_MIN, 
                            high=self.particle_cls.ORIENTATION_MAX, size=self.n)
        return np.vstack((p_offset, p_orientation)).T


    def _init_weights(self):
        """ Initialize to a uniform distribution"""
        w = np.ones((self.n,))
        w /= np.sum(w)
        return w


    def _init_state(self):
        """ Requires particles and weights to have been initialized."""
        return self._calc_state()


    def _update(self, measurement):
        """ Perform a complete update step.
            Args:
                measurement 
            Returns:
                self.state (State)

            Algorithm for Particle Filter:
            def f (S, U, Z): # S is particles, U is control, Z is measurement
                S' = empty set
                for i = 0 ... n: # each new particle
                    Sample J ~ {w} with replacement # weights of current S
                    Estimate x' ~ p(x' | U, s_j)
                    W' = p(z|x') # new particle weight is likelihood given estimate
                    S' = S' u {< x', w'>} # add new particle to set
                for i = 0 ... n: # for each particle,  normalize weights
                    W_i /= n

        """
        assert measurement.shape == (self.state_size,)
        resampled_indices = np.random.choice(a=self.n, size=self.n, replace=True, p=self.weights)
        resampled_particles = self.particles[resampled_indices, :]
        self.particles = self._apply_control(resampled_particles)
        self.weights = 1 /( 1 + ParticleFilterModel._distance(self.particle_cls, 
                            self.particles, measurement))
        self.weights /= np.sum(self.weights)
        self.state_matrix = self._calc_state()
        assert self.particles.shape == (self.n,self.state_size), self.particles.shape
        assert self.weights.shape == (self.n,), self.weights.shape
        assert self.state_matrix.shape == (self.state_size,), self.state_matrix.shape
        self.state = self.particle_cls.matrixToModel(self.state_matrix)
        self.last_measurement = measurement
        return self.state


    def _apply_control(self, resampled_particles):
        """ Apply control model (motion of the plane).
            For now, model as Gaussian noise applied to each particle,
                which prevents all particles collapsing to a single point.
        """
        noise1 = np.random.normal(0, self.VAR_OFFSET, (self.n, 1))
        noise2 = np.random.normal(0, self.VAR_ORIENTATION, (self.n, 1))
        noise = np.hstack((noise1, noise2))
        return resampled_particles + noise


    def _calc_state(self):
        """ Estimate the state given the current distribution of particles;
            Return the mean position.
        """
        return np.average(a=self.particles, axis=0, weights=self.weights) # for each column


    @staticmethod
    def _distance(particle_cls, new_particles, measurement):
        """ Get distance from each particle in the list to a measurement.
                Use squared distance. Average of 2 columns, for each row.
                Normalize by the expected variance of true values.
                Tune the Learning Rate to change the magnitude of the distance;
                    larger rate will cause particles to move more quickly.
            Args:
                new_particles (np.array): n x state_size list of particles
                measurement (np.array): state_size x 1 
        """
        transform = np.array([1000/particle_cls.OFFSET_RANGE, 1000/particle_cls.ORIENTATION_RANGE])
        normalized_particles = new_particles * transform
        normalized_measurement = measurement * transform
        distances = ((normalized_particles - normalized_measurement) ** 2)
        answer = distances.mean(axis=1)
        return answer * ParticleFilterModel.LEARNING_RATE
